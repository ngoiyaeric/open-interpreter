---
title: Profiles
---

Profiles are a powerful way to customize your instance of Open Interpreter.

Profiles are Python files that configure Open Interpreter. A wide range of fields from the [model](/settings/all-settings#model-selection) to the [context window](/settings/all-settings#context-window) to the [message templates](/settings/all-settings#user-message-template) can be configured in a Profile. This allows you to save multiple variations of Open Interpreter to optimize for your specific use-cases.

You can access your Profiles by running `interpreter --profiles`. This will open the directory where all of your Profiles are stored.

To apply a Profile to an Open Interpreter session, you can run `interpreter --profile <name>`

# Example Profile

```Python
from interpreter import interpreter

interpreter.os = True
interpreter.llm.supports_vision = True

interpreter.llm.model = "gpt-4-vision-preview"

interpreter.llm.supports_functions = False
interpreter.llm.context_window = 110000
interpreter.llm.max_tokens = 4096
interpreter.auto_run = True
interpreter.loop = True
```

<Tip>
  There are many settings that can be configured. [See them all
  here](/settings/all-settings)
</Tip>

## Helpful settings for local models

Local models benefit from more coercion and guidance. This verbosity of adding extra context to messages can impact the conversational experience of Open Interpreter. The following settings allow templates to be applied to messages to improve the steering of the language model while maintaining the natural flow of conversation.

`interpreter.user_message_template` allows users to have their message wrapped in a template. This can be helpful steering a language model to a desired behaviour without needing the user to add extra context to their message.

`interpreter.always_apply_user_message_template` has all user messages to be wrapped in the template. If False, only the last User message will be wrapped.

`interpreter.code_output_template` wraps the output from the computer after code is run. This can help with nudging the language model to continue working or to explain outputs.

`interpreter.empty_code_output_template` is the message that is sent to the language model if code execution results in no output.
